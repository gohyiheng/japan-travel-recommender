# japan-travel-recommender

This project scraps cities information from japan-guide.com, a popular resource for tourist information about Japan. 
It extracts data about regions, prefectures, cities, ratings, visits, and recommendation levels, and saves them to a CSV file.
---

## WIP
- ~~Clean csv data file.~~
- ~~Create recommender to allow sorting of cities~~ based on popularity/ratings/mixture of popularity & rating/hidden. gems where cities have high rating but low visits count 
- Build mvp to showcase data.
- Include geolocation to cities to generate itinerary based on filters.
    - ~~geodesic (without API) less accurate~~
    - openrouteservice (API) more accurate
- Include attractions and places of intrest within each cities. 
- Create database for easier viewing/querying/saving of 
- Allow users to select how they would want to view the data (cities or attractions)
---

## Files
- **`japan_scraper.py`**  
  Main script that does the scrapping.
    - Loads region URLs using `scrap_regions.py`.
    - Scrapes each region's destinations (prefecture/cities).
    - Extracts metadata: name, link, description, rating, visits, and recommendation tier.
    - Outputs all results into a CSV file (`japan_cities.csv`).

- **`scrap_regions.py`**  
    Helper module that scrapes the list of all travel regions in Japan.  

- **`scrap_regions.py`**  
    Contains information with the following columns (
    Region,	Prefecture,	City, Link, Description, Rating, Visits, Recommendation). 

- **`data_prep_cities.ipynb`**  
    - Prepares the csv for use in the recommender system. 
    - Handles missing value (okinawa being a prefecture and a region), duplicate values if any, NaN values.
    - Exports to a new csv for the recommender system. 

- **`generate_recommendations_cities.ipynb`**  
    - Takes the csv generated by data_prep_cities.ipynb. 
    - Removes the ',' in visits value and converts visits from object to int.
    - Summarise the ratings & visits column and created data visualisation such as histogram and scatterplot to get a better understanding of the data.
    - Normalise the value of ratings & visits, create 3 recommendation type:
        - balanced - average of both scores.
        - popular - skews calculation towards places with more visits (65/35).
        - hidden gems - skews calculation towards places with a higher rating (65/35).
    - Displays data to make sure that its sensible to a normal user, (example - balanced should not show places with extremely low visits).
    - Exports data to csv for displaying on website.

- **`insert_geolocation.py`**  
    - uses Nominatim to get Longitude and Latitude of a city and writes to csv `japan_cities_geolocation.csv`.

- **`clean_geolocation.py`**  
    - cleans NaN values from `japan_cities_geolocation.csv` generates a new csv file `japan_cities_geolocation_cleaned.csv`.

- **`calculate_dist_cities.py`**  
    Calculates distance between 2 cities using harvesine and geodesic distance.

- **`save_distance_geodesic.py`**  
    Uses geodesic distance to calculate all city pairs from `japan_cities_geolocation_cleaned.csv` and generates a new csv file `geodesic_city_distances.csv`.
---

Run the program

npm run dev - frontend
uvicorn main:app --reload - backend

remove dupes: 

/WITH duplicates AS (SELECT "Id", ROW_NUMBER() OVER (PARTITION BY region, prefecture, city ORDER BY "Id") AS rn FROM cities) DELETE FROM cities WHERE "Id" IN (SELECT "Id" FROM duplicates WHERE rn > 1);
